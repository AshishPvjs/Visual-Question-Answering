{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(1)\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models as torchmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,epochs,trainloader,validationloader,verbose=False,plot=False,save=False,loc='chpt'):\n",
    "    '''\n",
    "    args:\n",
    "    \n",
    "    model: pytorch model\n",
    "    epochs: no of epochs\n",
    "    trainloader: Data loader for train set\n",
    "    validationloader: Data loader for validation set\n",
    "    verbose: False/True : If true will print progress as we train \n",
    "    plot: If true will plot the model's loss, accuracy graphs.\n",
    "    \n",
    "    returns: \n",
    "            list[train_acc,valid_acc,train_loss,valid_loss]\n",
    "    '''\n",
    "    # LOSS FUNCTION\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss(reduction='mean')\n",
    "    \n",
    "    #OPTIMIZER\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_loss, valid_loss = [], []\n",
    "    train_acc,valid_acc=[],[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # TRAINING \n",
    "    for epoch in range(1, epochs+1):\n",
    "        if verbose:\n",
    "            print('epoch',epoch)\n",
    "        ## training part \n",
    "        model.train()\n",
    "        ta=0\n",
    "        correctt=0\n",
    "        correctv=0\n",
    "        losst=0\n",
    "        lossv=0\n",
    "        t_k=0\n",
    "        v_k=0\n",
    "        c=1\n",
    "        nb=math.ceil(X_train.shape[0]/batch_size)\n",
    "        for data,data2, target in trainloader:\n",
    "            if verbose:\n",
    "                print('\\r'+'batch_no :'+str(c)+' /'+str(nb),end='')\n",
    "            c+=1\n",
    "            t_k=t_k+1\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data,data2)\n",
    "            loss = loss_function(output, target.argmax(dim=1))\n",
    "            loss.backward()\n",
    "            losst=losst+loss.item()\n",
    "            optimizer.step()\n",
    "            #print(output)\n",
    "            #print(data.shape)\n",
    "            acc=(output.argmax(dim=1) == target.argmax(dim=1)).float().sum().item()\n",
    "            correctt =correctt + acc\n",
    "        train_acc.append(correctt/X_train.shape[0])\n",
    "        train_loss.append(loss.item())\n",
    "        if verbose or (epoch-1)%10==0:\n",
    "            print('train_loss',losst/t_k)\n",
    "            print('training accuracy',correctt/X_train.shape[0])\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        ## VALIDATION CHECK  \n",
    "        model.eval()\n",
    "        \n",
    "\n",
    "        for data,data2, target in validationloader:\n",
    "            v_k=v_k+1\n",
    "            output = model(data,data2)\n",
    "            loss = loss_function(output, target.argmax(dim=1))\n",
    "            lossv=lossv+loss.item()\n",
    "            accv=(output.argmax(dim=1) == target.argmax(dim=1)).float().sum().item()\n",
    "            correctv =correctv + accv\n",
    "        valid_loss.append(lossv/v_k+1)\n",
    "        valid_acc.append(correctv/X_val.shape[0])\n",
    "        \n",
    "        if verbose or (epoch-1)%10==0:\n",
    "            print('valid_loss',lossv/v_k+1)\n",
    "            print('validation accuracy',correctv/X_val.shape[0])\n",
    "            \n",
    "            \n",
    "    # SAVING CHECKPOINT\n",
    "    \n",
    "    if save:\n",
    "        torch.save({\n",
    "                'epoch': epochs,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'model':model\n",
    "                }, loc)\n",
    "    \n",
    "    print('train_loss',losst/t_k)\n",
    "    print('valid_loss',lossv/v_k+1)\n",
    "    print('training accuracy',correctt/X_train.shape[0])\n",
    "    print('validation accuracy',correctv/X_val.shape[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #PLOTTING \n",
    "    if plot:\n",
    "        epc=np.arange(1,epochs+1)\n",
    "        plt.plot(epc,train_acc)\n",
    "        plt.plot(epc,valid_acc)\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(epc,train_loss)\n",
    "        plt.plot(epc,valid_loss)\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "    return train_acc,valid_acc,train_loss,valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,x_test_i,x_text_t,y_test):\n",
    "    '''\n",
    "    args:\n",
    "    \n",
    "    model: pytorch model\n",
    "    x_test: test  set features\n",
    "    y_test: test set labels\n",
    "    \n",
    "    returns:\n",
    "            -\n",
    "    prints:\n",
    "         accuracy\n",
    "         precision\n",
    "         recall\n",
    "         f-score\n",
    "         confusion matrix\n",
    "\n",
    "    '''\n",
    "    out=np.zeros((y_test.shape))\n",
    "    ind=0\n",
    "    loss_function = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    x_vl = torch.tensor(x_test_i, dtype=torch.long,device=device)\n",
    "    x_vl_t = torch.tensor(x_test_t, dtype=torch.long,device=device)\n",
    "    y_vl = torch.tensor(y_test, dtype=torch.float32,device=device)\n",
    "    testt = TensorDataset(x_vl,x_vl_t, y_vl)\n",
    "    testloader = DataLoader(testt, batch_size=128)\n",
    "    \n",
    "    model.eval()\n",
    "    v_k=0\n",
    "    lossv=0\n",
    "    correctv=0\n",
    "    y_out=[]\n",
    "    for data,data2, target in testloader:\n",
    "        ind_l=ind+target.shape[0]\n",
    "        v_k=v_k+1\n",
    "        output = model(data,data2)\n",
    "        out2=output.cpu()\n",
    "        out2=out2.detach().numpy()\n",
    "        out2=np.squeeze(out2)\n",
    "        #print(out2.shape,'aaa')\n",
    "        #print(out[ind:ind_l].shape,'aaaaa')\n",
    "        #print(ind,ind_l)\n",
    "        out[ind:ind_l]=out2\n",
    "        ind=ind_l\n",
    "        accv=(output.argmax(dim=1) == target.argmax(dim=1)).float().sum().item()\n",
    "        correctv =correctv + accv\n",
    "    print('accuracy')\n",
    "    print(correctv/x_test.shape[0])\n",
    "    y_true=y_test.argmax(axis=1)\n",
    "    y_pred=out.argmax(axis=1)\n",
    "    print('confusion matrix :\\n',confusion_matrix(y_true,y_pred),'\\n')\n",
    "    print('f1 score matrix :\\n',f1_score(y_true,y_pred,average='micro'),'\\n')\n",
    "    print('precision_score :\\n',precision_score(y_true,y_pred,pos_label=1,average='micro'),'\\n')\n",
    "    print('recall_score :\\n',recall_score(y_true,y_pred,pos_label=1,average='micro'),'\\n')\n",
    "    print('classification_report :\\n',classification_report(y_true,y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_EXT(vgg):\n",
    "    \n",
    "    return nn.Sequential((*list(vgg.children())[:-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASIC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class base_enc(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim,feat_ext_model,\n",
    "                 hidden_size_lstm,emb_w=None,emb_Train=False,feat_ext_Train=True,dropout=0.5):\n",
    "        super(base_enc,self).__init__()\n",
    "        \n",
    "        #IMAGE FEATURE EXTRACTOR \n",
    "        self.feature_extractor = feat_ext_model \n",
    "        '''\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = feat_ext_Train\n",
    "        \n",
    "        '''\n",
    "        self.conv_linear1=nn.Linear(25088,4096)\n",
    "        self.conv_linear2=nn.Linear(4096,2000)\n",
    "        #TEXT FEATURE EXTRACTOR \n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if emb_w is not None:\n",
    "            et = torch.tensor(emb_w, dtype=torch.float32,device=device)\n",
    "            self.embedding.weight = nn.Parameter(et)\n",
    "            self.embedding.weight.requires_grad = emb_Train\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.h_size=hidden_size_lstm\n",
    "        self.embed_size=embedding_dim\n",
    "        self.lstm = nn.LSTM(self.embed_size, self.h_size)        \n",
    "        self.text_linear1= nn.Linear(self.h_size, 2000)\n",
    "        \n",
    "        # General \n",
    "        self.nn1=nn.Linear(4000,500)\n",
    "        self.nn2=nn.Linear(500,2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "        \n",
    "    def img_feat_ext(self,image):\n",
    "        im1= self.feature_extractor(image)\n",
    "        #print(im1.shape)\n",
    "        im1=im1.view(im1.size(0), -1)\n",
    "        im2=self.relu(self.conv_linear1(im1))\n",
    "        return self.relu(self.conv_linear2(im2))\n",
    "    \n",
    "    def text_feat_ext(self,text):\n",
    "        h_embedding = self.dropout(self.embedding(text))       \n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        last_state, _ = torch.max(h_lstm, 1)   \n",
    "        return self.relu(self.text_linear1(last_state))\n",
    "  \n",
    "        \n",
    "    def forward(self, image,text):\n",
    "                \n",
    "        image_emb=self.img_feat_ext(image)\n",
    "        text_emb=self.text_feat_ext(text)\n",
    "        \n",
    "        ######## Concatenating feature embeddings\n",
    "        \n",
    "        #print(image_emb.shape)\n",
    "        joint_emb=torch.cat((image_emb, text_emb), 1)\n",
    "        #print(joint_emb.shape)\n",
    "        \n",
    "        out1=self.relu(self.nn1(joint_emb))\n",
    "        out2=self.nn2(out1)\n",
    "    \n",
    "      \n",
    "        return self.softmax(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DATA INTO MEMORY\n",
    "\n",
    "if we have numpy arrays of training images, training text, and class labels it will be easier to load.\n",
    "\n",
    "#### images of shape (no ofinstances ,3,224,224)\n",
    "\n",
    "#### text of shape ( no of instances ,fixed_text_length_n).  ie(no_of_instances,(idx_word1,idx_word2,............,idx_word_n))\n",
    "\n",
    "#### labels of shape (no of instances, class idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(X_train_images,batch_no,batch_size=64): #batch number starting from 0,1,2,3.. batch size default = 64\n",
    "    data={}\n",
    "    start_in= batch_no*batch_size\n",
    "    end_in= (batch_no+1)*batch_size\n",
    "    #print (start_in, end_in)\n",
    "    count = 0\n",
    "    for i in X_train_images:\n",
    "        if ((count >=start_in) and (count <end_in)): \n",
    "            data.update({i: X_train_images[i]}) \n",
    "        count +=1;\n",
    "    return data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch_img(file_loc,list):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_images=np.load('../data/X_train_img.npy')\n",
    "X_train_text=np.load('../data/X_train_text.npy')\n",
    "y_train=np.load('../data/y_train.npy')\n",
    "X_train_idx=np.load('../data/train_img_map.npy')\n",
    "\n",
    "#X_test_images=np.load('../data/X_test_img.npy')\n",
    "X_test_text=np.load('../data/X_test_text.npy')\n",
    "y_test=np.load('../data/y_test2.npy')\n",
    "X_test_idx=np.load('../data/test_img_map.npy')\n",
    "\n",
    "#X_val_images=np.load('../data/X_val_img.npy')\n",
    "X_val_text=np.load('../data/X_val_text.npy')\n",
    "y_val=np.load('../data/y_val2.npy')\n",
    "X_val_idx=np.load('../data/val_img_map.npy')\n",
    "\n",
    "\n",
    "#emb_w=np.load('../data/word_embeddings.npy')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DATA INTO GPU AND CREATING DATA ITERATORS \n",
    "\n",
    "we can load into GPU batch by batch if encounter gpu size issues, but it will be slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=batch_size\n",
    "x_tr_t = torch.tensor(X_train_text,dtype=torch.long,device=device)\n",
    "y_tr = torch.tensor(y_train,dtype=torch.long,device=device)\n",
    "x_tr_idx=torch.tensor(X_train_idx,dtype=torch.long,device=device)\n",
    "train = TensorDataset(x_tr_t, y_tr,x_tr_idx)\n",
    "trainloader = DataLoader(train, batch_size=batch_size)\n",
    "\n",
    "x_vl_t = torch.tensor(X_val_text, dtype=torch.long,device=device)\n",
    "y_vl = torch.tensor(y_val, dtype=torch.long,device=device)\n",
    "x_vl_idx=torch.tensor(X_val_idx,dtype=torch.long,device=device)\n",
    "valid = TensorDataset(x_vl_t, y_vl,x_vl_idx)\n",
    "validloader = DataLoader(valid, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING PRETRAINED VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16 = torchmodels.vgg16_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cpu\")\n",
    "VGG_16=VGG_EXT(VGG16)\n",
    "model_basic=base_enc(5000,300,VGG_16,60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=torch.rand(1,3,224,224)\n",
    "text=torch.zeros([1, 5], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:67: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4844, 0.5156]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_basic.forward(img,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=train_model(model_basic,epochs,trainloader,validloader,plot=True,verbose=False,save=True,loc='./checkpoints/basic_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_t=np.load('../data/questions_val.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80541,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=0 \n",
    "for i in range(Q_t.shape[0]):\n",
    "    l=l+len(Q_t[i])\n",
    "l=l/Q_t.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.82927949739884"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=0\n",
    "s=15\n",
    "for i in range(Q_t.shape[0]):\n",
    "    if len(Q_t[i])> s:\n",
    "        m=m+1\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_t_pad=np.zeros((Q_t.shape[0],15))\n",
    "for i in range(Q_t.shape[0]):\n",
    "    pad_idx=0\n",
    "    pad_idx=15-len(Q_t[i])\n",
    "    if(pad_idx<0):\n",
    "        pad_idx=0\n",
    "    for j in range(len(Q_t[i])):\n",
    "        if j>14:\n",
    "            break\n",
    "        else:\n",
    "            Q_t_pad[i][pad_idx+j]=Q_t[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 5.000e+00,\n",
       "        1.200e+01, 4.000e+00, 8.582e+03]), [5, 12, 4, 8582])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_t_pad[0],Q_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/Question_val_pad.npy',Q_t_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_map=np.load('../data/question_image_map_val.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'393225001': 0,\n",
       " '393225002': 0,\n",
       " '109229002': 1,\n",
       " '109229012': 1,\n",
       " '131089001': 2,\n",
       " '131089003': 2,\n",
       " '131089004': 2,\n",
       " '262162000': 3,\n",
       " '262162004': 3,\n",
       " '262162006': 3,\n",
       " '262162007': 3,\n",
       " '262162008': 3,\n",
       " '262162010': 3,\n",
       " '262162012': 3,\n",
       " '262162013': 3,\n",
       " '262162014': 3,\n",
       " '262162015': 3,\n",
       " '262162016': 3,\n",
       " '262162019': 3,\n",
       " '262162020': 3,\n",
       " '262162024': 3,\n",
       " '262162025': 3,\n",
       " '393243000': 4,\n",
       " '393243002': 4,\n",
       " '262175000': 5,\n",
       " '262175003': 5,\n",
       " '131108000': 6,\n",
       " '131108002': 6,\n",
       " '42001': 7,\n",
       " '131115000': 8,\n",
       " '131115001': 8,\n",
       " '524333001': 9,\n",
       " '524333002': 9,\n",
       " '524333003': 9,\n",
       " '524333004': 9,\n",
       " '122208000': 10,\n",
       " '122208001': 10,\n",
       " '393266001': 11,\n",
       " '262197002': 12,\n",
       " '262197003': 12,\n",
       " '262197004': 12,\n",
       " '262197006': 12,\n",
       " '393271000': 13,\n",
       " '393271001': 13,\n",
       " '262200000': 14,\n",
       " '393274001': 15,\n",
       " '393274002': 15,\n",
       " '393274005': 15,\n",
       " '393274006': 15,\n",
       " '393274007': 15,\n",
       " '393277000': 16,\n",
       " '393277002': 16,\n",
       " '393277006': 16,\n",
       " '393277007': 16,\n",
       " '393277011': 16,\n",
       " '393277013': 16,\n",
       " '393277014': 16,\n",
       " '393282000': 17,\n",
       " '393282002': 17,\n",
       " '393282004': 17,\n",
       " '393282006': 17,\n",
       " '393282007': 17,\n",
       " '393284000': 18,\n",
       " '393284004': 18,\n",
       " '393284005': 18,\n",
       " '393284006': 18,\n",
       " '393284007': 18,\n",
       " '393284011': 18,\n",
       " '393284014': 18,\n",
       " '74000': 19,\n",
       " '131152000': 20,\n",
       " '131152003': 20,\n",
       " '262227000': 21,\n",
       " '262227002': 21,\n",
       " '262228003': 22,\n",
       " '262229002': 23,\n",
       " '131159001': 24,\n",
       " '524382002': 25,\n",
       " '262242002': 26,\n",
       " '262242004': 26,\n",
       " '262242005': 26,\n",
       " '262242006': 26,\n",
       " '262242007': 26,\n",
       " '262242008': 26,\n",
       " '131171000': 27,\n",
       " '131171002': 27,\n",
       " '262161001': 28,\n",
       " '262161002': 28,\n",
       " '262161009': 28,\n",
       " '262161014': 28,\n",
       " '262161017': 28,\n",
       " '262161020': 28,\n",
       " '524392001': 29,\n",
       " '262262000': 30,\n",
       " '262262001': 30,\n",
       " '262274004': 31,\n",
       " '262274005': 31,\n",
       " '262274006': 31,\n",
       " '262274007': 31,\n",
       " '262275002': 32,\n",
       " '262275003': 32,\n",
       " '133001': 33,\n",
       " '131207002': 34,\n",
       " '131207003': 34,\n",
       " '131207007': 34,\n",
       " '136000': 35,\n",
       " '262284002': 36,\n",
       " '524431002': 37,\n",
       " '524436000': 38,\n",
       " '524436002': 38,\n",
       " '524436004': 38,\n",
       " '524436005': 38,\n",
       " '393372000': 39,\n",
       " '393372001': 39,\n",
       " '393372002': 39,\n",
       " '393372004': 39,\n",
       " '393372009': 39,\n",
       " '393372016': 39,\n",
       " '393372017': 39,\n",
       " '393372018': 39,\n",
       " '393372019': 39,\n",
       " '393372021': 39,\n",
       " '393372022': 39,\n",
       " '524450002': 40,\n",
       " '524450003': 40,\n",
       " '524450010': 40,\n",
       " '524450011': 40,\n",
       " '524450013': 40,\n",
       " '524450016': 40,\n",
       " '524450018': 40,\n",
       " '524450022': 40,\n",
       " '164002': 41,\n",
       " '524456001': 42,\n",
       " '524456002': 42,\n",
       " '524459002': 43,\n",
       " '262323003': 44,\n",
       " '262325001': 45,\n",
       " '262325002': 45,\n",
       " '262334000': 46,\n",
       " '192001': 47,\n",
       " '393410000': 48,\n",
       " '393410002': 48,\n",
       " '393410003': 48,\n",
       " '393410006': 48,\n",
       " '393410007': 48,\n",
       " '393410009': 48,\n",
       " '393411000': 49,\n",
       " '196001': 50,\n",
       " '196004': 50,\n",
       " '262347000': 51,\n",
       " '262347001': 51,\n",
       " '262347003': 51,\n",
       " '131276000': 52,\n",
       " '393421002': 53,\n",
       " '393421004': 53,\n",
       " '393423002': 54,\n",
       " '131280002': 55,\n",
       " '262353001': 56,\n",
       " '262353002': 56,\n",
       " '131282001': 57,\n",
       " '131282002': 57,\n",
       " '131282004': 57,\n",
       " '524502003': 58,\n",
       " '262360000': 59,\n",
       " '262360004': 59,\n",
       " '262360005': 59,\n",
       " '524507000': 60,\n",
       " '524507002': 60,\n",
       " '131295001': 61,\n",
       " '131295003': 61,\n",
       " '262371000': 62,\n",
       " '262376000': 63,\n",
       " '262376002': 63,\n",
       " '241003': 64,\n",
       " '262386002': 65,\n",
       " '262386004': 65,\n",
       " '262386005': 65,\n",
       " '262386006': 65,\n",
       " '262386008': 65,\n",
       " '262386013': 65,\n",
       " '262386015': 65,\n",
       " '262386016': 65,\n",
       " '262386018': 65,\n",
       " '262386020': 65,\n",
       " '262386021': 65,\n",
       " '262386022': 65,\n",
       " '262386024': 65,\n",
       " '262386025': 65,\n",
       " '262386026': 65,\n",
       " '262386027': 65,\n",
       " '262386029': 65,\n",
       " '262386030': 65,\n",
       " '262386031': 65,\n",
       " '262386034': 65,\n",
       " '262386036': 65,\n",
       " '262386039': 65,\n",
       " '262386041': 65,\n",
       " '524533001': 66,\n",
       " '262391000': 67,\n",
       " '262391001': 67,\n",
       " '262391003': 67,\n",
       " '262391006': 67,\n",
       " '524536001': 68,\n",
       " '524536002': 68,\n",
       " '524536003': 68,\n",
       " '524536006': 68,\n",
       " '192047000': 69,\n",
       " '192047001': 69,\n",
       " '192047004': 69,\n",
       " '262394000': 70,\n",
       " '262394001': 70,\n",
       " '262396002': 71,\n",
       " '393469000': 72,\n",
       " '393469001': 72,\n",
       " '257001': 73,\n",
       " '257002': 73,\n",
       " '257003': 73,\n",
       " '393478001': 74,\n",
       " '393478002': 74,\n",
       " '393478003': 74,\n",
       " '131335000': 75,\n",
       " '131335001': 75,\n",
       " '131335002': 75,\n",
       " '131335004': 75,\n",
       " '262425000': 76,\n",
       " '262425001': 76,\n",
       " '262425002': 76,\n",
       " '262425003': 76,\n",
       " '283006': 77,\n",
       " '285000': 78,\n",
       " '285001': 78,\n",
       " '285002': 78,\n",
       " '524575000': 79,\n",
       " '524575001': 79,\n",
       " '524575002': 79,\n",
       " '524577001': 80,\n",
       " '524577010': 80,\n",
       " '524577014': 80,\n",
       " '524577015': 80,\n",
       " '524577025': 80,\n",
       " '524577028': 80,\n",
       " '294000': 81,\n",
       " '294002': 81,\n",
       " '294005': 81,\n",
       " '294006': 81,\n",
       " '294010': 81,\n",
       " '393511000': 82,\n",
       " '393511002': 82,\n",
       " '262440005': 83,\n",
       " '262440006': 83,\n",
       " '262440007': 83,\n",
       " '262440008': 83,\n",
       " '262440009': 83,\n",
       " '262440011': 83,\n",
       " '393513000': 84,\n",
       " '393513001': 84,\n",
       " '393513003': 84,\n",
       " '393523000': 85,\n",
       " '393523001': 85,\n",
       " '393523002': 85,\n",
       " '393523004': 85,\n",
       " '524601001': 86,\n",
       " '524601004': 86,\n",
       " '524601006': 86,\n",
       " '524601010': 86,\n",
       " '524601011': 86,\n",
       " '131386002': 87,\n",
       " '262460002': 88,\n",
       " '131390000': 89,\n",
       " '131390001': 89,\n",
       " '262466000': 90,\n",
       " '262466003': 90,\n",
       " '524611003': 91,\n",
       " '524611006': 91,\n",
       " '262471000': 92,\n",
       " '262471005': 92,\n",
       " '262471007': 92,\n",
       " '21900001': 93,\n",
       " '21900002': 93,\n",
       " '21900003': 93,\n",
       " '393547000': 94,\n",
       " '262476000': 95,\n",
       " '524621001': 96,\n",
       " '524621002': 96,\n",
       " '524621005': 96,\n",
       " '524621006': 96,\n",
       " '524621010': 96,\n",
       " '524621011': 96,\n",
       " '524621012': 96,\n",
       " '524621013': 96,\n",
       " '524621015': 96,\n",
       " '524621016': 96,\n",
       " '524621020': 96,\n",
       " '524621023': 96,\n",
       " '524621029': 96,\n",
       " '338000': 97,\n",
       " '524627000': 98,\n",
       " '524627001': 98,\n",
       " '393557001': 99,\n",
       " '131418000': 100,\n",
       " '131418002': 100,\n",
       " '524637001': 101,\n",
       " '524637005': 101,\n",
       " '524637006': 101,\n",
       " '524638000': 102,\n",
       " '524638001': 102,\n",
       " '393569000': 103,\n",
       " '524642000': 104,\n",
       " '524642004': 104,\n",
       " '357001': 105,\n",
       " '131431005': 106,\n",
       " '131431008': 106,\n",
       " '360000': 107,\n",
       " '360002': 107,\n",
       " '262505000': 108,\n",
       " '262505002': 108,\n",
       " '262505003': 108,\n",
       " '262505005': 108,\n",
       " '393578000': 109,\n",
       " '393578001': 109,\n",
       " '262509000': 110,\n",
       " '262509002': 110,\n",
       " '262509003': 110,\n",
       " '262509006': 110,\n",
       " '262509008': 110,\n",
       " '393583004': 111,\n",
       " '524656001': 112,\n",
       " '524656002': 112,\n",
       " '436968006': 113,\n",
       " '436968007': 113,\n",
       " '262514000': 114,\n",
       " '262514001': 114,\n",
       " '262514003': 114,\n",
       " '131444000': 115,\n",
       " '131444002': 115,\n",
       " '524665001': 116,\n",
       " '262522000': 117,\n",
       " '262522001': 117,\n",
       " '262522002': 117,\n",
       " '131453000': 118,\n",
       " '131453001': 118,\n",
       " '131453004': 118,\n",
       " '387002': 119,\n",
       " '524681000': 120,\n",
       " '395002': 121,\n",
       " '131138000': 122,\n",
       " '131138002': 122,\n",
       " '131138003': 122,\n",
       " '400001': 123,\n",
       " '400003': 123,\n",
       " '524694000': 124,\n",
       " '524694001': 124,\n",
       " '524694002': 124,\n",
       " '524702001': 125,\n",
       " '524702002': 125,\n",
       " '415000': 126,\n",
       " '415002': 126,\n",
       " '546203001': 127,\n",
       " '546203002': 127,\n",
       " '131494001': 128,\n",
       " '131494002': 128,\n",
       " '131497000': 129,\n",
       " '131497002': 129,\n",
       " '428001': 130,\n",
       " '393647003': 131,\n",
       " '393647005': 131,\n",
       " '262576002': 132,\n",
       " '524725000': 133,\n",
       " '524725002': 133,\n",
       " '393659000': 134,\n",
       " '131516000': 135,\n",
       " '131516001': 135,\n",
       " '131516002': 135,\n",
       " '524742002': 136,\n",
       " '131527000': 137,\n",
       " '131527001': 137,\n",
       " '393674000': 138,\n",
       " '393674001': 138,\n",
       " '393674005': 138,\n",
       " '459002': 139,\n",
       " '459003': 139,\n",
       " '262605001': 140,\n",
       " '262605003': 140,\n",
       " '262605007': 140,\n",
       " '262605008': 140,\n",
       " '262605011': 140,\n",
       " '262605012': 140,\n",
       " '262608001': 141,\n",
       " '262608002': 141,\n",
       " '262608003': 141,\n",
       " '262608004': 141,\n",
       " '262608005': 141,\n",
       " '262608007': 141,\n",
       " '262608008': 141,\n",
       " '262609000': 142,\n",
       " '262609001': 142,\n",
       " '262609005': 142,\n",
       " '262609009': 142,\n",
       " '262609012': 142,\n",
       " '262609013': 142,\n",
       " '131539000': 143,\n",
       " '131539001': 143,\n",
       " '131539002': 143,\n",
       " '131539003': 143,\n",
       " '131539004': 143,\n",
       " '131539006': 143,\n",
       " '131539007': 143,\n",
       " '131539008': 143,\n",
       " '131539009': 143,\n",
       " '472000': 144,\n",
       " '472001': 144,\n",
       " '472002': 144,\n",
       " '472004': 144,\n",
       " '472005': 144,\n",
       " '474002': 145,\n",
       " '393692002': 146,\n",
       " '262626000': 147,\n",
       " '262626001': 147,\n",
       " '131556000': 148,\n",
       " '131556001': 148,\n",
       " '131557000': 149,\n",
       " '131557003': 149,\n",
       " '131557006': 149,\n",
       " '131557007': 149,\n",
       " '486000': 150,\n",
       " '486001': 150,\n",
       " '524775008': 151,\n",
       " '488000': 152,\n",
       " '488002': 152,\n",
       " '393710000': 153,\n",
       " '393710001': 153,\n",
       " '262642000': 154,\n",
       " '262642001': 154,\n",
       " '502000': 155,\n",
       " '502001': 155,\n",
       " '502002': 155,\n",
       " '502003': 155,\n",
       " '393720001': 156,\n",
       " '393720002': 156,\n",
       " '393720005': 156,\n",
       " '393720006': 156,\n",
       " '262651001': 157,\n",
       " '262651002': 157,\n",
       " '131581000': 158,\n",
       " '131581001': 158,\n",
       " '262654000': 159,\n",
       " '262654001': 159,\n",
       " '524799001': 160,\n",
       " '262658001': 161,\n",
       " '262658002': 161,\n",
       " '109313000': 162,\n",
       " '520001': 163,\n",
       " '520002': 163,\n",
       " '520005': 163,\n",
       " '520006': 163,\n",
       " '131593001': 164,\n",
       " '131593002': 164,\n",
       " '131597002': 165,\n",
       " '131597005': 165,\n",
       " '131597006': 165,\n",
       " '262672000': 166,\n",
       " '262672001': 166,\n",
       " '524822002': 167,\n",
       " '524822006': 167,\n",
       " '524822008': 167,\n",
       " '524822014': 167,\n",
       " '524822018': 167,\n",
       " '536001': 168,\n",
       " '536006': 168,\n",
       " '536009': 168,\n",
       " '536012': 168,\n",
       " '536013': 168,\n",
       " '536016': 168,\n",
       " '536017': 168,\n",
       " '536018': 168,\n",
       " '536020': 168,\n",
       " '536022': 168,\n",
       " '536023': 168,\n",
       " '536024': 168,\n",
       " '536030': 168,\n",
       " '262682000': 169,\n",
       " '262682003': 169,\n",
       " '262682008': 169,\n",
       " '262682011': 169,\n",
       " '262682012': 169,\n",
       " '262682014': 169,\n",
       " '262682016': 169,\n",
       " '262682019': 169,\n",
       " '262682021': 169,\n",
       " '131611002': 170,\n",
       " '131611006': 170,\n",
       " '131611007': 170,\n",
       " '131611009': 170,\n",
       " '131611015': 170,\n",
       " '131611017': 170,\n",
       " '131611018': 170,\n",
       " '131612002': 171,\n",
       " '262686000': 172,\n",
       " '262686004': 172,\n",
       " '262686007': 172,\n",
       " '544001': 173,\n",
       " '544005': 173,\n",
       " '544007': 173,\n",
       " '544009': 173,\n",
       " '544016': 173,\n",
       " '544017': 173,\n",
       " '544018': 173,\n",
       " '544020': 173,\n",
       " '196699002': 174,\n",
       " '393768001': 175,\n",
       " '524844000': 176,\n",
       " '524844005': 176,\n",
       " '524844006': 176,\n",
       " '524844009': 176,\n",
       " '524844012': 176,\n",
       " '524844013': 176,\n",
       " '524844018': 176,\n",
       " '524844019': 176,\n",
       " '262703005': 177,\n",
       " '393777000': 178,\n",
       " '393777002': 178,\n",
       " '393777005': 178,\n",
       " '524850002': 179,\n",
       " '564000': 180,\n",
       " '564001': 180,\n",
       " '569000': 181,\n",
       " '569002': 181,\n",
       " '569003': 181,\n",
       " '569004': 181,\n",
       " '569006': 181,\n",
       " '153013000': 182,\n",
       " '153013001': 182,\n",
       " '393794000': 183,\n",
       " '393804001': 184,\n",
       " '393804002': 184,\n",
       " '131661000': 185,\n",
       " '131661003': 185,\n",
       " '131661004': 185,\n",
       " '131661006': 185,\n",
       " '590001': 186,\n",
       " '590002': 186,\n",
       " '393809007': 187,\n",
       " '393809008': 187,\n",
       " '393809009': 187,\n",
       " '393809013': 187,\n",
       " '262738003': 188,\n",
       " '262738006': 188,\n",
       " '393811001': 189,\n",
       " '393814003': 190,\n",
       " '524887000': 191,\n",
       " '524887001': 191,\n",
       " '524889002': 192,\n",
       " '524889004': 192,\n",
       " '262746001': 193,\n",
       " '262758001': 194,\n",
       " '393836001': 195,\n",
       " '393836002': 195,\n",
       " '393838000': 196,\n",
       " '393838001': 196,\n",
       " '623001': 197,\n",
       " '623002': 197,\n",
       " '623003': 197,\n",
       " '393840002': 198,\n",
       " '393840003': 198,\n",
       " '626000': 199,\n",
       " '626002': 199,\n",
       " '632002': 200,\n",
       " '632003': 200,\n",
       " '632006': 200,\n",
       " '632008': 200,\n",
       " '632013': 200,\n",
       " '636001': 201,\n",
       " '636002': 201,\n",
       " '393857002': 202,\n",
       " '393857004': 202,\n",
       " '393857005': 202,\n",
       " '393857007': 202,\n",
       " '393857009': 202,\n",
       " '218561003': 203,\n",
       " '393864002': 204,\n",
       " '393864003': 204,\n",
       " '131725001': 205,\n",
       " '262800000': 206,\n",
       " '262800001': 206,\n",
       " '262800003': 206,\n",
       " '262800004': 206,\n",
       " '262800006': 206,\n",
       " '262800007': 206,\n",
       " '393874000': 207,\n",
       " '393874008': 207,\n",
       " '393874009': 207,\n",
       " '661002': 208,\n",
       " '661003': 208,\n",
       " '524954001': 209,\n",
       " '524954002': 209,\n",
       " '524957001': 210,\n",
       " '131743000': 211,\n",
       " '524962001': 212,\n",
       " '675002': 213,\n",
       " '524977001': 214,\n",
       " '524977002': 214,\n",
       " '692000': 215,\n",
       " '699000': 216,\n",
       " '699001': 216,\n",
       " '524992001': 217,\n",
       " '524992002': 217,\n",
       " '711003': 218,\n",
       " '711005': 218,\n",
       " '393928000': 219,\n",
       " '393928001': 219,\n",
       " '393928002': 219,\n",
       " '393928004': 219,\n",
       " '393928006': 219,\n",
       " '724000': 220,\n",
       " '724001': 220,\n",
       " '393942001': 221,\n",
       " '131800001': 222,\n",
       " '262873003': 223,\n",
       " '262873005': 223,\n",
       " '730001': 224,\n",
       " '730002': 224,\n",
       " '730004': 224,\n",
       " '87503000': 225,\n",
       " '131804000': 226,\n",
       " '525021000': 227,\n",
       " '525021001': 227,\n",
       " '525021002': 227,\n",
       " '525021006': 227,\n",
       " '525021007': 227,\n",
       " '525024000': 228,\n",
       " '525024001': 228,\n",
       " '525024002': 228,\n",
       " '525024003': 228,\n",
       " '525024010': 228,\n",
       " '131815000': 229,\n",
       " '131815004': 229,\n",
       " '131815006': 229,\n",
       " '262895000': 230,\n",
       " '262895001': 230,\n",
       " '262895002': 230,\n",
       " '262895004': 230,\n",
       " '262895005': 230,\n",
       " '262895006': 230,\n",
       " '262895009': 230,\n",
       " '262895010': 230,\n",
       " '262895013': 230,\n",
       " '262895015': 230,\n",
       " '262895018': 230,\n",
       " '262895019': 230,\n",
       " '262896000': 231,\n",
       " '262896005': 231,\n",
       " '43816000': 232,\n",
       " '43816001': 232,\n",
       " '43816002': 232,\n",
       " '43816004': 232,\n",
       " '43816005': 232,\n",
       " '43816007': 232,\n",
       " '43816008': 232,\n",
       " '43816009': 232,\n",
       " '43816011': 232,\n",
       " '43816014': 232,\n",
       " '43816020': 232,\n",
       " '43816021': 232,\n",
       " '43816022': 232,\n",
       " '43816024': 232,\n",
       " '43816026': 232,\n",
       " '43816027': 232,\n",
       " '262900001': 233,\n",
       " '262900002': 233,\n",
       " '757001': 234,\n",
       " '757003': 234,\n",
       " '757004': 234,\n",
       " '757006': 234,\n",
       " '757011': 234,\n",
       " '757012': 234,\n",
       " '757013': 234,\n",
       " '757015': 234,\n",
       " '757016': 234,\n",
       " '757018': 234,\n",
       " '757019': 234,\n",
       " '757020': 234,\n",
       " '757021': 234,\n",
       " '761000': 235,\n",
       " '761004': 235,\n",
       " '525050006': 236,\n",
       " '525050008': 236,\n",
       " '525050018': 236,\n",
       " '525050020': 236,\n",
       " '764002': 237,\n",
       " '764004': 237,\n",
       " '764005': 237,\n",
       " '393982000': 238,\n",
       " '393982002': 238,\n",
       " '525058003': 239,\n",
       " '525058004': 239,\n",
       " '525058005': 239,\n",
       " '525058007': 239,\n",
       " '525058009': 239,\n",
       " '525058010': 239,\n",
       " '525058013': 239,\n",
       " '525058014': 239,\n",
       " '525058015': 239,\n",
       " '772001': 240,\n",
       " '772002': 240,\n",
       " '775000': 241,\n",
       " '775002': 241,\n",
       " '775005': 241,\n",
       " '775009': 241,\n",
       " '393995001': 242,\n",
       " '131856000': 243,\n",
       " '785000': 244,\n",
       " '785002': 244,\n",
       " '785003': 244,\n",
       " '785004': 244,\n",
       " '785005': 244,\n",
       " '394002000': 245,\n",
       " '394002003': 245,\n",
       " '131203001': 246,\n",
       " '131203002': 246,\n",
       " '131203003': 246,\n",
       " '262933001': 247,\n",
       " '394009001': 248,\n",
       " '262938001': 249,\n",
       " '525083000': 250,\n",
       " '525083002': 250,\n",
       " '525087000': 251,\n",
       " '802001': 252,\n",
       " '802004': 252,\n",
       " '131882000': 253,\n",
       " '131882002': 253,\n",
       " '240434001': 254,\n",
       " '394033000': 255,\n",
       " '394033001': 255,\n",
       " '525106001': 256,\n",
       " '525106002': 256,\n",
       " '131895000': 257,\n",
       " '131895002': 257,\n",
       " '131895003': 257,\n",
       " '827001': 258,\n",
       " '525118000': 259,\n",
       " '525118001': 259,\n",
       " '525119002': 260,\n",
       " '525119003': 260,\n",
       " '525119008': 260,\n",
       " '394050001': 261,\n",
       " '836001': 262,\n",
       " '836002': 262,\n",
       " '262985000': 263,\n",
       " '262985004': 263,\n",
       " '262986000': 264,\n",
       " '262987000': 265,\n",
       " '131919001': 266,\n",
       " '131919002': 266,\n",
       " '131920000': 267,\n",
       " '262993002': 268,\n",
       " '394079000': 269,\n",
       " '131938002': 270,\n",
       " '131938004': 270,\n",
       " '131938006': 270,\n",
       " '131938007': 270,\n",
       " '131938008': 270,\n",
       " '131938009': 270,\n",
       " '525155000': 271,\n",
       " '525155002': 271,\n",
       " '263014002': 272,\n",
       " '263014003': 272,\n",
       " '263014004': 272,\n",
       " '263014008': 272,\n",
       " '263014010': 272,\n",
       " '263014014': 272,\n",
       " '263014015': 272,\n",
       " '872000': 273,\n",
       " '872002': 273,\n",
       " '872004': 273,\n",
       " '872005': 273,\n",
       " '873000': 274,\n",
       " '525162000': 275,\n",
       " '525162002': 275,\n",
       " '525162003': 275,\n",
       " '525170002': 276,\n",
       " '885003': 277,\n",
       " '885009': 277,\n",
       " '885010': 277,\n",
       " '885015': 277,\n",
       " '885018': 277,\n",
       " '885023': 277,\n",
       " '885031': 277,\n",
       " '885032': 277,\n",
       " '131965005': 278,\n",
       " '131965007': 278,\n",
       " '525183004': 279,\n",
       " '525184001': 280,\n",
       " '131969001': 281,\n",
       " '131969003': 281,\n",
       " '131969005': 281,\n",
       " '458903003': 282,\n",
       " '458903005': 282,\n",
       " '458903007': 282,\n",
       " '263052000': 283,\n",
       " '525202000': 284,\n",
       " '394131000': 285,\n",
       " '394131001': 285,\n",
       " '394131004': 285,\n",
       " '394133004': 286,\n",
       " '394133007': 286,\n",
       " '394133009': 286,\n",
       " '525208001': 287,\n",
       " '132001001': 288,\n",
       " '132001003': 288,\n",
       " '939000': 289,\n",
       " '394157002': 290,\n",
       " '132024000': 291,\n",
       " '132024001': 291,\n",
       " '132024005': 291,\n",
       " '132024008': 291,\n",
       " '132024009': 291,\n",
       " '132024010': 291,\n",
       " '132024011': 291,\n",
       " '546292001': 292,\n",
       " '546292002': 292,\n",
       " '525247000': 293,\n",
       " '525247001': 293,\n",
       " '962000': 294,\n",
       " '132037001': 295,\n",
       " '969003': 296,\n",
       " '132042003': 297,\n",
       " '974003': 298,\n",
       " '974004': 298,\n",
       " '263120000': 299,\n",
       " '263120001': 299,\n",
       " '263120003': 299,\n",
       " '263120004': 299,\n",
       " '415225000': 300,\n",
       " '525272000': 301,\n",
       " '525272001': 301,\n",
       " '525272003': 301,\n",
       " '985001': 302,\n",
       " '985004': 302,\n",
       " '985007': 302,\n",
       " '985011': 302,\n",
       " '985016': 302,\n",
       " '132059001': 303,\n",
       " '394206001': 304,\n",
       " '394206002': 304,\n",
       " '394206003': 304,\n",
       " '263136004': 305,\n",
       " '263136005': 305,\n",
       " '263136008': 305,\n",
       " '525286002': 306,\n",
       " '1000002': 307,\n",
       " '1000003': 307,\n",
       " '263146002': 308,\n",
       " '525297001': 309,\n",
       " '525297002': 309,\n",
       " '132084001': 310,\n",
       " '263163002': 311,\n",
       " '394240000': 312,\n",
       " '1029001': 313,\n",
       " '394246000': 314,\n",
       " '394246003': 314,\n",
       " '263177000': 315,\n",
       " '263178002': 316,\n",
       " '394251004': 317,\n",
       " '132116000': 318,\n",
       " '132116001': 318,\n",
       " '132121001': 319,\n",
       " '132121002': 319,\n",
       " '132121005': 319,\n",
       " '525344001': 320,\n",
       " '528142000': 321,\n",
       " '394275001': 322,\n",
       " '394275003': 322,\n",
       " '1063000': 323,\n",
       " '1063001': 323,\n",
       " '1063002': 323,\n",
       " '132136003': 324,\n",
       " '132136004': 324,\n",
       " '132136011': 324,\n",
       " '132136012': 324,\n",
       " '132136015': 324,\n",
       " '525354000': 325,\n",
       " '525354002': 325,\n",
       " '525354003': 325,\n",
       " '263211002': 326,\n",
       " '263211004': 326,\n",
       " '132143000': 327,\n",
       " '132143001': 327,\n",
       " '525361001': 328,\n",
       " '525361003': 328,\n",
       " '263223002': 329,\n",
       " '263223006': 329,\n",
       " '525369000': 330,\n",
       " '525369001': 330,\n",
       " '525369002': 330,\n",
       " '525369003': 330,\n",
       " '525369004': 330,\n",
       " '525369011': 330,\n",
       " '525371001': 331,\n",
       " '525371002': 331,\n",
       " '525373003': 332,\n",
       " '525373005': 332,\n",
       " '525376001': 333,\n",
       " '1089000': 334,\n",
       " '1089003': 334,\n",
       " '525381000': 335,\n",
       " '525381002': 335,\n",
       " '1103002': 336,\n",
       " '394322003': 337,\n",
       " '263251002': 338,\n",
       " '132182000': 339,\n",
       " '394328002': 340,\n",
       " '394328003': 340,\n",
       " '394334002': 341,\n",
       " '394334003': 341,\n",
       " '525420000': 342,\n",
       " '525420001': 342,\n",
       " '523780001': 343,\n",
       " '523780003': 343,\n",
       " '1138003': 344,\n",
       " '1146006': 345,\n",
       " '1146010': 345,\n",
       " '132219000': 346,\n",
       " '132219001': 346,\n",
       " '132219002': 346,\n",
       " '263292003': 347,\n",
       " '1149002': 348,\n",
       " '132223002': 349,\n",
       " '1153006': 350,\n",
       " '1153007': 350,\n",
       " '1153014': 350,\n",
       " '1153015': 350,\n",
       " '1153016': 350,\n",
       " '263299002': 351,\n",
       " '1164000': 352,\n",
       " '1164001': 352,\n",
       " '1171000': 353,\n",
       " '1171001': 353,\n",
       " '1176002': 354,\n",
       " '263323001': 355,\n",
       " '263323007': 355,\n",
       " '132272003': 356,\n",
       " '263346001': 357,\n",
       " '263346003': 357,\n",
       " '263346005': 357,\n",
       " '263346006': 357,\n",
       " '263346007': 357,\n",
       " '263346008': 357,\n",
       " '263346009': 357,\n",
       " '263346010': 357,\n",
       " '263346012': 357,\n",
       " '263346017': 357,\n",
       " '1205002': 358,\n",
       " '263351001': 359,\n",
       " '263351002': 359,\n",
       " '263351006': 359,\n",
       " '263355000': 360,\n",
       " '263355003': 360,\n",
       " '263355004': 360,\n",
       " '263359000': 361,\n",
       " '263359002': 361,\n",
       " '132288002': 362,\n",
       " '1228000': 363,\n",
       " '394449001': 364,\n",
       " '394449002': 364,\n",
       " '394458000': 365,\n",
       " '394458001': 365,\n",
       " '394458003': 365,\n",
       " '394460005': 366,\n",
       " '394460009': 366,\n",
       " '394460013': 366,\n",
       " '394460014': 366,\n",
       " '263393000': 367,\n",
       " '263393001': 367,\n",
       " '263393003': 367,\n",
       " '132328001': 368,\n",
       " '132329000': 369,\n",
       " '525546002': 370,\n",
       " '263403000': 371,\n",
       " '263403002': 371,\n",
       " '394478002': 372,\n",
       " '132336006': 373,\n",
       " '132336009': 373,\n",
       " '263412003': 374,\n",
       " '263412004': 374,\n",
       " '1270000': 375,\n",
       " '1270001': 375,\n",
       " '525559002': 376,\n",
       " '525568000': 377,\n",
       " '525568001': 377,\n",
       " '525568003': 377,\n",
       " '525568004': 377,\n",
       " '525568005': 377,\n",
       " '525568007': 377,\n",
       " '525568009': 377,\n",
       " '525568014': 377,\n",
       " '263425000': 378,\n",
       " '263425002': 378,\n",
       " '263428001': 379,\n",
       " '263428002': 379,\n",
       " '132362001': 380,\n",
       " ...}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_map_2=np.zeros((Q_t.shape[0])).astype('uint32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in  range(Q_t.shape[0]):\n",
    "    train_map_2[i]=int(train_map[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 398)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_map_2[999],train_map[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/question_image_map_train_array.npy',train_map_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
